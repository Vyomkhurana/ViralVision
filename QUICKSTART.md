# ğŸš€ ViralVision Quick Start Guide

## âš¡ Setup (5 minutes)

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure YouTube API
Create `.env` file:
```
YOUTUBE_API_KEY=your_key_here
```
Get your key: https://console.cloud.google.com/apis/credentials

---

## ğŸ¯ Complete Workflow

### Option A: Full Pipeline (Recommended for first time)
```bash
# 1. Collect YouTube trending videos
python src/data_collection.py

# 2. Process and create features
python src/preprocessing.py

# 3. Label videos (Low/Medium/Viral)
python src/labeling.py

# 4. Train ML model
python src/model_training.py

# 5. Launch web app
streamlit run app/streamlit_app.py
```

### Option B: Quick Demo (If you already have labeled data)
```bash
# Train model
python src/model_training.py

# Launch app
streamlit run app/streamlit_app.py
```

---

## ğŸ“Š What Each Script Does

| Script | Purpose | Input | Output |
|--------|---------|-------|--------|
| `data_collection.py` | Fetches YouTube data | YouTube API | `data/raw/*.csv` |
| `preprocessing.py` | Engineers features | Raw CSV | `data/processed/processed_videos.csv` |
| `labeling.py` | Assigns virality labels | Processed CSV | `data/processed/labeled_videos.csv` |
| `model_training.py` | Trains basic model | Labeled CSV | `models/*.pkl` |
| `model_training_advanced.py` | Optimizes with tuning | Labeled CSV | `models/*.pkl` (better) |
| `predict.py` | Predicts new videos | Video data | Predictions |
| `visualize_data.py` | Creates charts | Labeled CSV | `visualizations/*.png` |
| `streamlit_app.py` | Web interface | Models | Web app |

---

## ğŸ¨ Using the Web App

### Start the app:
```bash
streamlit run app/streamlit_app.py
```

### Three tabs available:

1. **ğŸ¯ Single Prediction**
   - Enter video details manually
   - Get instant prediction with confidence scores
   - See probability breakdown

2. **ğŸ“Š Batch Prediction**
   - Upload CSV with multiple videos
   - Get predictions for all videos
   - Download results

3. **ğŸ“ˆ Analytics**
   - View dataset statistics
   - Explore patterns and trends
   - Understand what makes videos viral

---

## ğŸ”§ Common Tasks

### Make a Single Prediction
```python
from src.predict import predict_virality

video = {
    "title": "Amazing Tutorial!",
    "description": "Learn something cool",
    "tags": "tutorial|learning|howto",
    "view_count": 10000,
    "like_count": 500,
    "comment_count": 50,
    "published_at": "2026-01-08T12:00:00Z"
}

result = predict_virality(video)
print(f"{result['predicted_label']} ({result['confidence']:.1f}%)")
```

### Predict Multiple Videos
```python
from src.predict import predict_batch

df = predict_batch(
    csv_path="my_videos.csv",
    output_path="predictions.csv"
)
```

### Analyze Title Quality
```python
from src.utils import analyze_title_quality

result = analyze_title_quality("Your Title Here")
print(f"Score: {result['score']}/100")
print(f"Quality: {result['quality']}")
for rec in result['recommendations']:
    print(f"  â€¢ {rec}")
```

---

## ğŸ“ˆ Improving the Model

### Run Advanced Training
```bash
python src/model_training_advanced.py
```
This will:
- Test multiple algorithms (Random Forest, Gradient Boosting)
- Tune hyperparameters with GridSearchCV
- Select the best performing model
- Save the optimized model

Takes ~5-10 minutes but improves accuracy!

---

## ğŸ“Š Generate Visualizations

```bash
python src/visualize_data.py
```

Creates in `visualizations/`:
- Distribution charts
- Engagement analysis
- Time pattern heatmaps
- Correlation matrices
- Summary statistics
- Insights report

---

## ğŸ’¡ Pro Tips

### 1. Collect More Data
```bash
# Collect 200 videos instead of 50
python src/data_collection.py  # Edit max_results in the file
```

### 2. Adjust Virality Thresholds
In `src/labeling.py`, modify:
```python
low_threshold = df["view_count"].quantile(0.50)  # Bottom 50%
viral_threshold = df["view_count"].quantile(0.80)  # Top 20%
```

### 3. Add Custom Features
In `src/preprocessing.py`, add your own features:
```python
df["my_feature"] = df["column"].apply(my_function)
```

Then update `model_training.py` to include it.

---

## ğŸ› Troubleshooting

### "Model files not found"
**Solution:** Run `python src/model_training.py` first

### "No raw CSV files found"
**Solution:** Run `python src/data_collection.py` first

### "YouTube API quota exceeded"
**Solution:** 
- Wait 24 hours for quota reset
- Use multiple API keys
- Reduce max_results in data_collection.py

### Import errors
**Solution:**
```bash
pip install -r requirements.txt --upgrade
```

---

## ğŸ“š File Requirements

### For data_collection.py
- `.env` file with `YOUTUBE_API_KEY`

### For model_training.py
- `data/processed/labeled_videos.csv`

### For predict.py
- `models/virality_model.pkl`
- `models/label_encoder.pkl`
- `models/feature_names.pkl`

### For streamlit app
- All model files (generated by model_training.py)

---

## ğŸ¯ Success Metrics

After training, you should see:
- âœ… Accuracy: 75-85%
- âœ… F1-Score: 0.75-0.85
- âœ… Cross-validation: Consistent across folds
- âœ… Confusion matrix: Diagonal values high

Lower performance might indicate:
- âŒ Not enough training data (collect more)
- âŒ Imbalanced classes (adjust thresholds)
- âŒ Need feature engineering (add more features)

---

## ğŸš€ Next Steps

1. **âœ… Complete the full pipeline once**
2. **ğŸ“Š Generate visualizations to understand data**
3. **ğŸ¨ Explore the web app**
4. **âš¡ Run advanced training for better accuracy**
5. **ğŸ¯ Make predictions on your own videos!**

---

## ğŸ“ Getting Help

- Check error messages carefully
- Review the main README.md
- Ensure all dependencies are installed
- Verify file paths are correct
- Check that data exists before each step

---

**Happy Predicting! ğŸ¬ğŸš€**
